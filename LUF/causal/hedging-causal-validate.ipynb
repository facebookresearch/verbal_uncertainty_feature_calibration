{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfb90c6-abd8-4a08-bc61-590c450aa133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import argparse\n",
    "import itertools\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import os\n",
    "import json\n",
    "os.environ['HUGGING_FACE_HUB_TOKEN'] = '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'\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/home/jadeleiyu/mechanistic-uncertainty-calibrate/LUF/')\n",
    "from utils import get_qa_system_prompt\n",
    "\n",
    "model_name = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "dataset_names = [\n",
    "    'nq_open', 'trivia_qa', 'pop_qa'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb948dce-2939-42cf-8398-899554bb28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ling_uncertainty_features(ds_name, model, tokenizer, device, results_merged, n_example_per_class=500):\n",
    "    ds_idx = [i for i in range(len(results_merged)) if results_merged[i]['dataset name'] == ds_name]\n",
    "    questions = [results_merged[i]['question'] for i in ds_idx]\n",
    "\n",
    "    ling_uncertainty_scores = np.array([\n",
    "        results_merged[i]['linguistic uncertainty'] for i in ds_idx\n",
    "    ])\n",
    "    ling_uncertain_idx = np.argsort(ling_uncertainty_scores)[-n_example_per_class:]\n",
    "    ling_certain_idx = np.argsort(ling_uncertainty_scores)[:n_example_per_class]\n",
    "\n",
    "    sys_prompt = get_qa_system_prompt('uncertainty')\n",
    "    Hs_questions_uncertain_ling = []\n",
    "    Hs_questions_certain_ling = []\n",
    "\n",
    "    for i in tqdm(ling_uncertain_idx):\n",
    "        question = questions[i]\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\\nAnswer: \"},\n",
    "        ]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=True, add_generation_prompt=True, \n",
    "            return_tensors=\"pt\", return_dict=True\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Hs_i = model(**inputs.to(device), output_hidden_states=True).hidden_states\n",
    "            Hs_i = torch.cat(Hs_i, dim=0)[1:,-1].cpu()\n",
    "            Hs_questions_uncertain_ling.append(Hs_i)\n",
    "\n",
    "    for i in tqdm(ling_certain_idx):\n",
    "        question = questions[i]\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\\nAnswer: \"},\n",
    "        ]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=True, add_generation_prompt=True, \n",
    "            return_tensors=\"pt\", return_dict=True\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Hs_i = model(**inputs.to(device), output_hidden_states=True).hidden_states\n",
    "            Hs_i = torch.cat(Hs_i, dim=0)[1:,-1].cpu()\n",
    "            Hs_questions_certain_ling.append(Hs_i)\n",
    "    \n",
    "    Hs_questions_uncertain_ling = torch.stack(Hs_questions_uncertain_ling)\n",
    "    Hs_questions_certain_ling = torch.stack(Hs_questions_certain_ling)\n",
    "    ling_uncertain_feats = Hs_questions_uncertain_ling.mean(0) - Hs_questions_certain_ling.mean(0)\n",
    "\n",
    "    return ling_uncertain_feats\n",
    "\n",
    "\n",
    "def remove_all_hooks(model):\n",
    "    \"\"\"Remove all forward/backward hooks from the model.\"\"\"\n",
    "    for module in model.modules():\n",
    "        module._forward_hooks.clear()\n",
    "        module._forward_pre_hooks.clear()\n",
    "        module._backward_hooks.clear()\n",
    "\n",
    "def register_feature_ablation_hook(model, Hs_feature, feat_vals_def, layer_idx):\n",
    "    for l in layer_idx:\n",
    "        device_idx_l = device_idx_l = model.hf_device_map[f\"model.layers.{l}\"]\n",
    "        h_feature_l = Hs_feature[l].to(f\"cuda:{device_idx_l}\")  # (h_dim)\n",
    "        h_feature_l = h_feature_l / torch.sqrt(h_feature_l.pow(2).sum(-1))\n",
    "\n",
    "        def make_feature_ablation_hook(h_feature_l, feat_val_def):\n",
    "            def feature_ablation_hook(module, inputs, outputs):\n",
    "                if isinstance(outputs, tuple):\n",
    "                    outputs_0 = outputs[0]   # (B, seq_len, h_dim)\n",
    "                    if outputs_0.shape[1] > 1:\n",
    "                        outputs_0 -= h_feature_l * torch.matmul(outputs_0, h_feature_l).unsqueeze(-1)\n",
    "                        outputs_0 += feat_val_def * h_feature_l\n",
    "                    return (outputs_0,) + outputs[1:]\n",
    "                else:\n",
    "                    if outputs.shape[1] > 1:\n",
    "                        outputs -= h_feature_l * torch.matmul(outputs, h_feature_l).unsqueeze(-1)\n",
    "                        outputs += feat_val_def * h_feature_l\n",
    "                    return outputs\n",
    "            return feature_ablation_hook\n",
    "\n",
    "        model.model.layers[l].register_forward_hook(\n",
    "            make_feature_ablation_hook(h_feature_l, feat_vals_def[l])\n",
    "        )\n",
    "\n",
    "\n",
    "def register_feature_projection_hook(model, Hs_feature, layer_idx, fp_cache):\n",
    "    for l in layer_idx:\n",
    "        device_idx_l = device_idx_l = model.hf_device_map[f\"model.layers.{l}\"]\n",
    "        h_feature_l = Hs_feature[l].to(f\"cuda:{device_idx_l}\")  # (h_dim)\n",
    "        h_feature_l = h_feature_l / torch.sqrt(h_feature_l.pow(2).sum(-1))\n",
    "\n",
    "        def make_fp_hook(h_feature_l, l):\n",
    "            def fp_hook(module, inputs, outputs):\n",
    "                if isinstance(outputs, tuple):\n",
    "                    outputs_0 = outputs[0]   # (B, seq_len, h_dim)\n",
    "                    if outputs_0.shape[1] > 1:\n",
    "                        fp = torch.matmul(outputs_0[:, -1], h_feature_l).mean().cpu()\n",
    "                        fp_cache[l].append(fp)\n",
    "                    \n",
    "                else:\n",
    "                    if outputs.shape[1] > 1:\n",
    "                        fp = torch.matmul(outputs[:, -1], h_feature_l).mean().cpu()\n",
    "                        fp_cache[l].append(fp)\n",
    "                    \n",
    "            return fp_hook\n",
    "\n",
    "        model.model.layers[l].register_forward_hook(make_fp_hook(h_feature_l, l))\n",
    "\n",
    "\n",
    "def get_mean_activation_features(model, tokenizer, layers_to_fp, features, questions, sys_prompt):\n",
    "    remove_all_hooks(model)\n",
    "    torch.cuda.empty_cache()\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    layers_to_fp = np.arange(28) if 'gemma' in model.config.model_type else np.arange(32)\n",
    "\n",
    "    fp_cache = {l:[] for l in layers_to_fp}\n",
    "    register_feature_projection_hook(\n",
    "        model, features, layers_to_fp, fp_cache\n",
    "    )\n",
    "\n",
    "    for question in tqdm(questions):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\\nAnswer: \"},\n",
    "        ]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=True, add_generation_prompt=True, \n",
    "            return_tensors=\"pt\", return_dict=True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            model(**inputs.to('cuda'))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    remove_all_hooks(model)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    fp_cache = {\n",
    "        l : torch.stack(fps)\n",
    "        for l, fps in fp_cache.items()\n",
    "    }\n",
    "\n",
    "    return fp_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279eb5e3-53e8-4f4a-8af2-584f6c62a919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:41<00:00, 10.32s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "\n",
    "### load LM and tokenizer ###\n",
    "device = torch.device('cuda')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=torch.float16, device_map='auto'\n",
    ")\n",
    "model.eval();\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2584bc7-774b-4b51-a7cd-f8ddf1a9f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_short = model_name.split('/')[-1]\n",
    "with open(f'qa-eval-results/{model_name_short}-ling-sem-uncertainty.json', 'r') as f:\n",
    "    results_merged = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24166760-9b47-4c3d-a5d2-bf633b5af3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                       | 0/1431 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1431/1431 [01:08<00:00, 20.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1431/1431 [01:05<00:00, 21.71it/s]\n"
     ]
    }
   ],
   "source": [
    "######## get hedging features ########\n",
    "# ds_name = 'nq_open'\n",
    "# ds_name = 'trivia_qa'\n",
    "# ds_name = 'pop_qa'\n",
    "job_id = 1\n",
    "ds_name = dataset_names[job_id]\n",
    "ds_idx = [i for i in range(len(results_merged)) if results_merged[i]['dataset name'] == ds_name]\n",
    "questions = [results_merged[i]['question'] for i in ds_idx]\n",
    "n_example_per_class = int(0.1 * len(questions))\n",
    "ling_uncertain_feats = get_ling_uncertainty_features(\n",
    "    ds_name, model, tokenizer, device, results_merged,\n",
    "    n_example_per_class=n_example_per_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f5755-110f-4176-8cd3-3c0530b63b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d94ebc-7700-47f8-9f4b-1866e0432ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1431/1431 [02:06<00:00, 11.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1431/1431 [02:09<00:00, 11.08it/s]\n"
     ]
    }
   ],
   "source": [
    "sys_prompt = get_qa_system_prompt('uncertainty')\n",
    "layers_to_fa = np.arange(28) if 'gemma' in model.config.model_type else np.arange(32)\n",
    "\n",
    "ling_uncertainty_scores = np.array([\n",
    "    results_merged[i]['linguistic uncertainty'] for i in ds_idx\n",
    "])\n",
    "ling_uncertain_idx = np.argsort(ling_uncertainty_scores)[-n_example_per_class:]\n",
    "ling_certain_idx = np.argsort(ling_uncertainty_scores)[:n_example_per_class]\n",
    "questions_uncertain = [questions[i] for i in ling_uncertain_idx]\n",
    "questions_certain = [questions[i] for i in ling_certain_idx]\n",
    "\n",
    "luf_cache_uncertain = get_mean_activation_features(\n",
    "    model, tokenizer, layers_to_fa, ling_uncertain_feats, questions_uncertain, sys_prompt\n",
    ")\n",
    "luf_cache_certain = get_mean_activation_features(\n",
    "    model, tokenizer, layers_to_fa, ling_uncertain_feats, questions_certain, sys_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63dcc45e-70fa-4c2d-b887-eb57fd2b72c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14319/14319 [14:48<00:00, 16.11it/s]\n"
     ]
    }
   ],
   "source": [
    "luf_cache_all = get_mean_activation_features(\n",
    "    model, tokenizer, layers_to_fa, ling_uncertain_feats, questions, sys_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6be5b24c-9707-43e8-8bf6-f3ed3d8ba881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "lu_corrs = []\n",
    "for l in range(32):\n",
    "    corr_l = spearmanr(luf_cache_all[l].numpy(), ling_uncertainty_scores)\n",
    "    lu_corrs.append(corr_l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e2e563b-7e5e-40b3-a104-185cda940049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Corr(Hedgeness, Ling.Uncertain.Feat.)')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABWxUlEQVR4nO3deViU5f4G8HtmYBh2RPZFQdxXEJHc0gKXLNOsk62alpblcsIlPZWe6iQtv8xSj5a5pZWWmXbKTEUxLZLEXREVUEDZt2GdgZn39wc6RaDy4gzvzHB/rmsuZ95l5maamC/P87zPIxMEQQARERGRlZBLHYCIiIjImFjcEBERkVVhcUNERERWhcUNERERWRUWN0RERGRVWNwQERGRVWFxQ0RERFbFRuoALU2v1+PatWtwdnaGTCaTOg4RERE1gSAIKCsrg5+fH+TyW7fNtLri5tq1awgMDJQ6BhERETVDZmYmAgICbnlMqytunJ2dAdS9OS4uLhKnISIioqZQq9UIDAw0fI/fSqsrbm50Rbm4uLC4ISIisjBNGVLCAcVERERkVVjcEBERkVVhcUNERERWhcUNERERWRUWN0RERGRVWNwQERGRVWFxQ0RERFaFxQ0RERFZFRY3REREZFVY3BAREZFVYXFDREREVoXFDREREVmVVrdwJhER3TmdXoC2Vg+tTo+a6zcHpQ1cVDZNWtiQyJRY3BARWQhBEFCjE1BVo4OmRoeqGh2qa/TX/9XV266pqSs4NNcLEG3tX25/eaz5274a3Z/7b9yvqRXq7v+lmNELjWe0s5HDy8UOXs4qeDrZXb9vB0/n69uc67a1dbSDQs4iiEyDxQ0RkZFoa/XIVVfjWkkVskurca20Crml1dDU6lGrF6DT1xUJOr1geFz3rx61uuv7//K4RqdHdY0e1X8pXm5WVEjNViFDjU6AplaPzKIqZBZV3fJ4uQxo61RX+Hi7qNC+rQOCPRwR7OGIoLaO8HOzZ/FDzcbihoioCXR6AXll1bhWUo3s0ipkl9QVL9nXH18rrUZBuQZCCxUfchmgslXA3lYBla0CKls57JUKqGzqHtvZyKG8cVP85b6NHHaKv+9TwFYhq9t3fbutom6f7V/Ot1XIDccpFdePsZHDRi6DTCZDdY0O+WUa5JVVI0+tQV6Z5s/HZRrDtsIKDfQCkH99/9lr6gY/n1IhR/u2Dgi6XvDcKHqCPRzh7WLHri+6JcmLm5UrV+L9999HTk4O+vTpg+XLl6N///43PX7ZsmVYtWoVMjIy4OHhgUceeQSxsbFQqVQtmJqIrFGlthYZRZW4XFCJjKIKXCmsrLsVVeBaSTV0TWg2UdrI4eeqgq+rPXzdVPB1VcFBaQOFXAYbuewv/8r/fKxouN1GIYON/HrBYiv/SxFT91ipkJvdF7zKVoFAdwcEujvc8rhanR5FFdq6gqesGtml1bhcUIH0gkpcLqxARmEltDo9LuaV42JeeYPzHZQKtG/riGAPB7Rv64iANvYIaOOAwDb28HOzh8pWYaofkSyEpMXN1q1bERMTg9WrVyMyMhLLli3DyJEjkZKSAi8vrwbHf/nll1iwYAHWrVuHgQMH4sKFC3jmmWcgk8mwdOlSCX4CIrI0JZVaXCn880v0SlElrhTWFTJ5ZZpbnquQy+DjUlew+LrZXy9iVPBzq/tS9XVVwd1RaXZFh7mxUcjh5aKCl4sKgGuD/Tq9gGslVUgvqDDcLhfW/ZtVXIVKrQ7J2WokZzds8QEAL2c7BLo7IKCNPQLbOPxZ/Ljbw9fVHkobXihs7WSC0FKNqA1FRkYiIiICK1asAADo9XoEBgZi5syZWLBgQYPjZ8yYgeTkZMTFxRm2zZkzB0eOHMHhw4cbfQ2NRgON5s9fWGq1GoGBgSgtLYWLi4uRfyIiMkcVmlqsOZSGTQlXUFihveWxrva2CGrrgHZtHev+da9rHQh0t4eXs4rjQCSmrdUjq7iuOE3Lryt2Mosq6/4trkSlVnfL82UywMdFBX83e7jY28LJzgZOKpu6f/96U9nA8fp957/cd7Kz4WdAImq1Gq6urk36/pas5Uar1SIpKQkLFy40bJPL5YiOjkZCQkKj5wwcOBCbN29GYmIi+vfvj7S0NOzatQtPP/30TV8nNjYWb7zxhtHzE5H5q9XpsfVoJj7cexEF5X/+kePtYof27o5o19ahXiHT3t0Rrg62Eiam21HayNHB0wkdPJ1wb9f6+wRBQHFlDbKKK5FZVFX3b3Fd4VN3q0R1jR7ZpXVdYc3V0csJU4cEY1yYP+xs2AVmjiRrubl27Rr8/f3x22+/YcCAAYbt8+fPx8GDB3HkyJFGz/v4448xd+5cCIKA2tpavPDCC1i1atVNX4ctN0StjyAI2HsuF+/sPo+0/AoAQFBbB8wb2RX3dvWCvZJfSK2RIAgoKNcis7gS2SXVKNfUoKy6FhUaHco1NSjX1KJco0N59V/ua2pQodGhrLoGNbr6X5feLnZ4bnAHPB7ZDk52kg9htXoW0XLTHPHx8ViyZAn++9//IjIyEpcuXcLs2bPx1ltv4fXXX2/0HDs7O9jZ2bVwUiKSyrGMYsTuSsYfl4sBAO6OSsyO6oTH+7fjWItWTiaTwfP6nDtoJ/58Ta0OpVU1+P7ENaw5lIZctQZv70rG8v0XMWlgEJ4ZGIS2Tvy+MQeStdxotVo4ODhg27ZtGDdunGH7pEmTUFJSgp07dzY4Z8iQIbjrrrvw/vvvG7Zt3rwZ06ZNQ3l5OeTy2//iElP5EZHlSC+owPs/n8eu0zkAAJWtHM8N7oDnh3aAs4pdTWRcmloddh6/htUHU5FWUNc6qLKVY0K/QDw3pMNtrxgj8Syi5UapVCI8PBxxcXGG4kav1yMuLg4zZsxo9JzKysoGBYxCUde8LOG4aCKSUGG5Bh/HXcQXRzJQqxcglwGPhAcgZngX+LhyiggyDTsbBR6NCMTD4QHYey4H/41PxamsUmxMuILNRzLwYB8/PD+0A7r68I9oKUjaLRUTE4NJkyahX79+6N+/P5YtW4aKigpMnjwZADBx4kT4+/sjNjYWADBmzBgsXboUYWFhhm6p119/HWPGjDEUOUTUOlRpdVj3azpWxaeiXFMLALiniydeua8rv1CoxSjkMozq6YuRPXyQkFqIVQdTcehiAb47fhXfHb+KqK5emD4sBP2C3KWO2qpIWtxMmDAB+fn5WLRoEXJychAaGordu3fD29sbAJCRkVGvpea1116DTCbDa6+9hqtXr8LT0xNjxozB22+/LdWPQEQtTKcX8G1SFj7Ym4Jcdd3FAr38XbHwvq4Y2NFD4nTUWslkMgzs6IGBHT1wOqsUqw+mYteZbMSdz0Pc+TxEBLXB9GEhuKeLF+dBagGSznMjBY65IbJc6uoaPL02ESczSwAAAW3sMW9kF4zp7Qc55x4hM5NeUIFPf0nFt0lXodXpAQDdfF0w896OGNXDh59ZkcR8f7O4ISKLoKnV4Zl1fyAhrRAuKhvMiuqEpwe05zwjZPZy1dVYdzgdm3+/gorrkwx29HLCjHs64oHevrBR8Cq+pmBxcwssbogsj14v4J9bT+D7k9fgZGeDrc/fhR5+DaftJzJnJZVarPv1Mtb/mo6y6rpxYkFtHfDiPR3xUJg/bFnk3BKLm1tgcUNkeWJ3JeOTX9JgI5dh/eQIDOnkKXUkomZTV9dgU8IVfHYoDcWVNQAAfzd7TB8Wgn/0C2Br5E2wuLkFFjdElmXDr+n49//OAQCWPtoH4/sGSJyIyDgqNLX44sgVfPpLumF5EB8XFZ4f2gGP92/H1c3/hsXNLbC4IbIcu89kY/oXxyAIwLyRXfDSPR2ljkRkdNU1OnyVmIFPDqYhR1235pWHkx2m3R2MJyPbw5FLOwBgcXNLLG6ILMPRy0V48rMj0NTq8dRd7fDW2J68hJasmqZWh21JWfjvgVRcLakCALRxsMWzg4MxcWAQXFr5TNssbm6BxQ2R+buUV46HV/2G0qoaRHfzxidPh0PBy2aplajR6fHd8av474FLuFxYCQDwcrbD9zMGt+pZt8V8f3NoNhGZlTx1NSatS0RpVQ3C2rlh+eNhLGyoVbFVyPFov0DsixmKjx4LRaC7PfLKNFiw/RSXGmoiFjdEZDbKNbWYvOEPXC2pQrCHI9ZOioC9koMqqXWyUcgxNtQf6yZFQKmQIz4lH18fzZQ6lkVgcUNEZqFGp8f0zUk4e00NDyclNk7uD3dHpdSxiCTXydsZMSM6AwDe+iHZMB6Hbo7FDRFJThAEvPLtKRy6WAAHpQLrnolAu7YOUsciMhtTh3RA33ZuKNfU4pVt7J66HRY3RCS5D/ZcwPZjV6GQy7Dyyb7oHeAmdSQis6KQy/B//+gDOxs5Dl8qwOYjGVJHMmssbohIUl8cuYIVBy4BAGIf6oV7unhJnIjIPHXwdML8UV0B1M3anXH9SipqiMUNEUlm77lcvL7jDADgn9Gd8GhEoMSJiMzb5IFB6B/sjkqtDvO2nYRez+6pxrC4ISJJHMsoxsyvjkEvAI9FBGJ2VCepIxGZPblchv97pA8clAocSS/CxoTLUkcySyxuiKjFpRdU4LmNR1Fdo8c9XTzxn3GcfZioqdq1dcDC++q6p97dfR5p+eUSJzI/LG6IqEWVVdfguY1/oKhCi94BrljxRF/YKPiriEiMJyPbY1DHtqiu0WPuNyehY/dUPfyNQkQtRq8X8PLWE0jNr4CvqwqfTerHRQGJmkEul+G9R/rAyc4GxzJKsPZwmtSRzAqLGyJqMR/uu4B9yXmws5Hjk6fD4eXcetfJIbpT/m72eP2BbgCA/9tzARdzyyROZD5Y3BBRi/jpdDaW76+75Pudh3txLhsiI3i0XyCGdfGEtraue6pWp5c6kllgcUNEJnc+R40535wEADw3OBgPhQVInIjIOshkMrwzvjdcVDY4mVWKT35h9xTA4oaITKy4Qoupnx9FpVaHwR09sOD6VR5EZBw+rir8+8EeAIBl+y4gOVstcSLpsbghIpOp1ekx86vjyCyqQqC7PZY/HsYro4hM4KEwf0R380aNTsCcr0+iRqLuqXJNLX4+m4P4lDxJXv8GXqZARCbzzk/ncfhS3WKYayb2Qxuu8k1kEjKZDEvG98TRD4twLluNFfsv4eXhnU3+uoIgIK2gAgfO5yE+JR9H0gtRoxPQP9gdwyRcSoXFDRGZxPZjWfjscDoA4IN/9EFXHxeJExFZNy9nFd4a2xMzvzqOlQcuYXh3b/T0dzX661TX6PB7WiHiU/Kx/3weMorqr3HVvq0Devu7QhAEySbnbFZxk5GRgStXrqCyshKenp7o0aMH7OzsjJ2NiCzUqawSLNh+GgAw896OuK+Xr8SJiFqHB3r74qcz2dh1Ogdzvj6J72cOgp2N4o6fN7OoEvEpeTiQko/fUgtQXfNnt5dSIUdkh7qWmnu6eCLYw1HyGcebXNxcvnwZq1atwpYtW5CVlQVB+HM2RKVSiSFDhmDatGl4+OGHIZezT52otcov0+D5TUnQ1uoR1dULL0ebvmmciOrIZDK8NbYnjqQVISW3DB/tu2hYSbwpdHoBVTU6VGl1uJhXhviUfBw4n4eLefWXePB1VRmKmUEdPcxuMk6Z8Ncq5SZmzZqFjRs3YuTIkRgzZgz69+8PPz8/2Nvbo6ioCGfOnMGhQ4ewZcsWKBQKrF+/HhERES2RXzS1Wg1XV1eUlpbCxYXN5ETGpK3V44k1v+PolWJ08HTEjpcGwUVlK3UsolZn95kcvLA5CXIZMHFAEGr1elRq64qWqhqd4X6lthbVNXpUamtRqdVBU9v4QGSFXIbwdm0wrKsn7u3qhS7ezi3eOiPm+7tJxc3ChQsxd+5ctG3b9rYvvnv3blRWVmL8+PFNT9yCWNwQmc6/vjuNL49kwNnOBjtmDEKIp5PUkYharX9uOY4dJ64161yZDPBwssOQTh64t6sXhnT0hKuDtH+oGL24sSYsbohM44sjV/Dqd2cgkwHrJkXgnq7SXSlBRHWL1H5yMA1anR72tgo4KBWwVyqu37eBg1IB1fXtN/Y5KG1gb6uAylYu+biZvxPz/W1enWREZJH+uFyEf39/FgAwd0QXFjZEZsBZZYu5I7tIHUMSRhv5+69//QtTpkwx1tMRkYXILq3C9M3HUKMTcH8vX7w4LETqSETUyhmt5SYrKwuZmZnGejoisgDVNTo8vykJBeUadPVxxvv/6G12TdlE1PoYrbj5/PPPjfVURGQh/vXdaZzKKkUbB1usmdgPDkr2dBOR9ER3S33++efQaDQNtmu1WhY4RK3IuWtqbD92FQq5DCuf6ItAdwepIxERAWhGcTN58mSUlpY22F5WVobJkycbJRQRmb8953IAAPd08cLAjh4SpyEi+pPo4uZma0VkZWXB1dX4a1gQkXnaey4XADCiu7fESYiI6mtyB3lYWBhkMhlkMhmioqJgY/PnqTqdDunp6Rg1apRJQhKReckqrsTZa2rIZUBUN172TUTmpcnFzbhx4wAAJ06cwMiRI+Hk9OfMo0qlEkFBQXj44YeNHpCIzM++66024e3boK0TF80lIvPS5OJm8eLFAICgoCBMmDABKpXKZKGIyLztTb7RJeUjcRIiooZEX7c5adIkU+QgIgtRWlmD39OKAADDOd6GiMyQ6OJGp9Phww8/xNdff42MjAxotdp6+4uKiowWjojMz4GUPOj0Ajp5OSHIw1HqOEREDYi+WuqNN97A0qVLMWHCBJSWliImJgbjx4+HXC7Hv//9bxNEJCJzYrhKqgdbbYjIPIkubr744gusWbMGc+bMgY2NDR5//HF89tlnWLRoEX7//XdTZCQiM6Gp1SE+JQ8AMJzjbYjITIkubnJyctCrVy8AgJOTk2FCvwceeAA//vijcdMRkVn5LbUQFVodvJzt0Nuf81oRkXkSXdwEBAQgOzsbABASEoI9e/YAAP744w/Y2fGSUCJrdqNLanh3b8jlXCCTiMyT6OLmoYceQlxcHABg5syZeP3119GpUydMnDgRU6ZMMXpAIjIPer1Qr7ghIjJXoq+Weueddwz3J0yYgHbt2iEhIQGdOnXCmDFjjBqOiMzHyawS5Jdp4GRngwEhbaWOQ0R0U6KLm78bMGAABgwYYIwsRGTGbrTaDO3iCTsbhcRpiIhuTnS3FABs2rQJgwYNgp+fH65cuQIAWLZsGXbu3GnUcERkPvZwoUwishCii5tVq1YhJiYGo0ePRklJCXQ6HQDAzc0Ny5Yta1aIlStXIigoCCqVCpGRkUhMTLzpscOGDTMs4PnX2/3339+s1yai20svqMClvHLYyGUY1oULZRKReRNd3Cxfvhxr1qzBq6++CoXiz6bpfv364fTp06IDbN26FTExMVi8eDGOHTuGPn36YOTIkcjLy2v0+O3btyM7O9twO3PmDBQKBf7xj3+Ifm0iapq953IAAHd1aAtXe1uJ0xAR3Zro4iY9PR1hYWENttvZ2aGiokJ0gKVLl2Lq1KmYPHkyunfvjtWrV8PBwQHr1q1r9Hh3d3f4+PgYbnv37oWDgwOLGyIT2nOWV0kRkeUQXdwEBwfjxIkTDbbv3r0b3bp1E/VcWq0WSUlJiI6O/jOQXI7o6GgkJCQ06TnWrl2Lxx57DI6Oja9xo9FooFar692IqOkKyjVIyigGwOKGiCyD6KulYmJi8NJLL6G6uhqCICAxMRFfffUVYmNj8dlnn4l6roKCAuh0Onh71/+F6e3tjfPnz9/2/MTERJw5cwZr16696TGxsbF44403ROUioj/FJedCEICe/i7wc7OXOg4R0W2JLm6ee+452Nvb47XXXkNlZSWeeOIJ+Pn54aOPPsJjjz1miow3tXbtWvTq1Qv9+/e/6TELFy5ETEyM4bFarUZgYGBLxCOyCoaJ+7pxLSkisgxNLm70ej3k8rperCeffBJPPvkkKisrUV5eDi+v5l094eHhAYVCgdzc3Hrbc3Nz4eNz61+kFRUV2LJlC958881bHmdnZ8dlIYiaqVJbi0MXCwBwFXAishxNHnNja2tb7wqmefPmobq6utmFDQAolUqEh4cblnMA6oqouLi4204M+M0330Cj0eCpp55q9usT0a39cqEAmlo9AtrYo6uPs9RxiIiapMnFjSAI9R5/8sknKCkpueMAMTExWLNmDTZu3Ijk5GRMnz4dFRUVmDx5MgBg4sSJWLhwYYPz1q5di3HjxqFtW04DT2Qqf11LSibjQplEZBmavfzC34ud5powYQLy8/OxaNEi5OTkIDQ0FLt37zYMMs7IyDB0h92QkpKCw4cPG1YkJyLjq9Xpsf/8jVmJOd6GiCzHHa8tZQwzZszAjBkzGt0XHx/fYFuXLl2MVlwRUeOOXilGcWUN3BxsERHURuo4RERNJqq4WbRoERwcHADUzVHz9ttvw9XVtd4xS5cuNV46IpLMjS6pe7t4wUbRrGXoiIgk0eTi5u6770ZKSorh8cCBA5GWllbvGPbJE1kHQRAMxQ2vkiIiS9Pk4qax7iEisk4puWXIKKqE0kaOIZ08pY5DRCQK25qJqIG919eSGtLRA452ZjE0j4ioyYxW3OzcuROff/65sZ6OiCS0N5kLZRKR5TJacfPKK68Y5qYhIsuVXVqFU1mlkMmAqG4sbojI8hitvbkpC10Skfnbd30gcd92beDpzKVLiMjycMwNEdWz5xy7pIjIsjWr5aakpASJiYnIy8uDXq+vt2/ixIlGCUZELU9dXYPf0woBsLghIsslurj53//+hyeffBLl5eVwcXGpN7eNTCZjcUNkweJT8lGjExDi6YgQTyep4xARNYvobqk5c+ZgypQpKC8vR0lJCYqLiw23oqIiU2Qkohby50KZXEuKiCyX6OLm6tWrmDVrlmEZBiKyDtpaPeLP5wFglxQRWTbRxc3IkSNx9OhRU2QhIgn9nlaIMk0tPJzsEBboJnUcIqJmEz3m5v7778e8efNw7tw59OrVC7a2tvX2P/jgg0YLR0QtZ8+5HADA8O5ekMu5ThwRWS7Rxc3UqVMBAG+++WaDfTKZDDqd7s5TEVGLEgQB+86xS4qIrIPo4ubvl34TkeU7fbUUOepqOCgVGBjiIXUcIqI7wkn8iAh7ri+UObSzJ1S2ConTEBHdmSa13Hz88ceYNm0aVCoVPv7441seO2vWLKMEI6KWc+MS8BE92CVFRJZPJgiCcLuDgoODcfToUbRt2xbBwcE3fzKZDGlpaUYNaGxqtRqurq4oLS2Fi4uL1HGIJHelsAJD34+HQi5D0mvRcHNQSh2JiKgBMd/fTWq5SU9Pb/Q+EVm+G602/YPcWdgQkVXgmBuiVu7ghXwAQDSvkiIiK9GshTOzsrLw/fffIyMjA1qttt6+pUuXGiUYEZlerU6PpCvFAIBBHdtKnIaIyDhEFzdxcXF48MEH0aFDB5w/fx49e/bE5cuXIQgC+vbta4qMRGQiZ6+pUanVwdXeFp29nKWOQ0RkFKK7pRYuXIi5c+fi9OnTUKlU+Pbbb5GZmYmhQ4fiH//4hykyEpGJJKbXLXYbEdSGsxITkdUQXdwkJydj4sSJAAAbGxtUVVXByckJb775Jt59912jByQi0zliKG7cJU5CRGQ8oosbR0dHwzgbX19fpKamGvYVFBQYLxkRmZReL+Dolbripn8wixsish6ix9zcddddOHz4MLp164bRo0djzpw5OH36NLZv34677rrLFBmJyAQu5pWjpLIG9rYK9PR3lToOEZHRiC5uli5divLycgDAG2+8gfLycmzduhWdOnXilVJEFiTxcl2rTd/2brBVcFYIIrIeooubDh06GO47Ojpi9erVRg1ERC0jkeNtiMhKif5zrUOHDigsLGywvaSkpF7hQ0TmSxAE/JHO8TZEZJ1EFzeXL1+GTqdrsF2j0eDq1atGCUVEppVZVIUcdTVsFTKEBbaROg4RkVE1uVvq+++/N9z/+eef4er65wBEnU6HuLg4BAUFGTUcEZnGjfE2vfxdYa9USJyGiMi4mlzcjBs3znB/0qRJ9fbZ2toiKCgIH3zwgdGCEZHpJKbXdS33D+aSC0RkfZpc3Oj1egBAcHAwjh49irZt+UuRyFIlGsbbsEuKiKyPqDE3NTU16NChA4qKikyVh4hMLE9djcuFlZDJgPD2HExMRNZHVHFja2uLU6dOmSoLEbWAG+Ntuvq4wNXeVuI0RETGJ/pqqaeeegpr1641RRYiagE3LgGP5CXgRGSlRE/iV1tbi3Xr1mHfvn0IDw+Ho6Njvf2cpZjIvB3h/DZEZOVEFzdnzpxB3759AQAXLlyot08mkxknFRGZRGllDVJyywBwZmIisl6ii5sDBw6YIgcRtYCjV4ogCEAHD0d4OttJHYeIyCSavVrepUuX8PPPP6OqqgpA3XTuRGTebgwmZqsNEVkz0cVNYWEhoqKi0LlzZ4wePRrZ2dkAgGeffRZz5swxekAiMp5EjrcholZAdHHz8ssvw9bWFhkZGXBwcDBsnzBhAnbv3m3UcERkPJXaWpzOKgXA4oaIrJvoMTd79uzBzz//jICAgHrbO3XqhCtXrhgtGBEZ14mMEtTqBfi6qhDQxl7qOEREJiO65aaioqJei80NRUVFsLPjAEUic3XjEvCIIHde2UhEVk10cTNkyBB8/vnnhscymQx6vR7vvfce7rnnHqOGIyLj+eMyx9sQUesgulvqvffeQ1RUFI4ePQqtVov58+fj7NmzKCoqwq+//mqKjER0h7S1ehzLKAbAmYmJyPqJbrnp2bMnLly4gMGDB2Ps2LGoqKjA+PHjcfz4cYSEhJgiIxHdoTPXSlFdo0cbB1t09HKSOg4RkUmJbrkBAFdXV7z66qvGzkJEJpLI8TZE1IqIbrlZv349vvnmmwbbv/nmG2zcuNEooYjIuP7g/DZE1IqILm5iY2Ph4eHRYLuXlxeWLFkiOsDKlSsRFBQElUqFyMhIJCYm3vL4kpISvPTSS/D19YWdnR06d+6MXbt2iX5dotZCrxc4mJiIWhXR3VIZGRkIDg5usL19+/bIyMgQ9Vxbt25FTEwMVq9ejcjISCxbtgwjR45ESkoKvLy8Ghyv1WoxfPhweHl5Ydu2bfD398eVK1fg5uYm9scgajVScsugrq6Fo1KB7r4uUschIjI50cWNl5cXTp06haCgoHrbT548ibZt24p6rqVLl2Lq1KmYPHkyAGD16tX48ccfsW7dOixYsKDB8evWrUNRURF+++032NraAkCDHERU343xNn3bt4GNotnLyRERWQzRv+kef/xxzJo1CwcOHIBOp4NOp8P+/fsxe/ZsPPbYY01+Hq1Wi6SkJERHR/8ZRi5HdHQ0EhISGj3n+++/x4ABA/DSSy/B29sbPXv2xJIlS6DT6W76OhqNBmq1ut6NqDUxrCfFxTKJqJUQ3XLz1ltv4fLly4iKioKNTd3per0eEydOFDXmpqCgADqdDt7e3vW2e3t74/z5842ek5aWhv379+PJJ5/Erl27cOnSJbz44ouoqanB4sWLGz0nNjYWb7zxRpNzEVkTQRAMK4FzvA0RtRaiixulUomtW7firbfewsmTJ2Fvb49evXqhffv2pshXj16vh5eXFz799FMoFAqEh4fj6tWreP/9929a3CxcuBAxMTGGx2q1GoGBgSbPSmQOLhdWIr9MA6VCjj6BblLHISJqEc2a5wYAOnfujM6dOzf7hT08PKBQKJCbm1tve25uLnx8fBo9x9fXF7a2tlAoFIZt3bp1Q05ODrRaLZRKZYNz7OzsuOYVtVo3LgHvE+gKla3iNkcTEVkH0cWNTqfDhg0bEBcXh7y8POj1+nr79+/f36TnUSqVCA8PR1xcHMaNGwegrmUmLi4OM2bMaPScQYMG4csvv4Rer4dcXjdc6MKFC/D19W20sCFq7Y5wfhsiaoVEFzezZ8/Ghg0bcP/996Nnz553NNtpTEwMJk2ahH79+qF///5YtmwZKioqDFdPTZw4Ef7+/oiNjQUATJ8+HStWrMDs2bMxc+ZMXLx4EUuWLMGsWbOanYHImt2Y3yaCg4mJqBURXdxs2bIFX3/9NUaPHn3HLz5hwgTk5+dj0aJFyMnJQWhoKHbv3m0YZJyRkWFooQGAwMBA/Pzzz3j55ZfRu3dv+Pv7Y/bs2XjllVfuOAuRtckprUZGUSXkMiC8fRup4xARtRiZIAiCmBP8/PwQHx9/R+NtpKRWq+Hq6orS0lK4uHBCM7Je35+8hllfHUdPfxf8MHOI1HGIiO6ImO9v0fPczJkzBx999BFE1kRE1MIS0wsBAP2DxE2uSURk6UR3Sx0+fBgHDhzATz/9hB49ehhmCr5h+/btRgtHRM2XyMHERNRKiS5u3Nzc8NBDD5kiCxEZSXGFFhdyywEAEUEcb0NErYvo4mb9+vWmyEFERnTjKqmOXk5o68R5noiodeEqekRWiJeAE1Fr1uSWmzZt2jQ6p42rqys6d+6MuXPnYvjw4UYNR0TNc2O8TSTH2xBRK9Tk4mbZsmWNbi8pKUFSUhIeeOABbNu2DWPGjDFWNiJqhgpNLc5cUwMAIljcEFEr1OTiZtKkSbfcHxoaitjYWBY3RBI7llEMnV6Av5s9/N3spY5DRNTijDbm5oEHHsD58+eN9XRE1Ex/8BJwImrljFbcaDQaLl5JZAa4WCYRtXZGK27Wrl2L0NBQYz0dETWDplaH45klAFjcEFHr1eQxNzExMY1uLy0txbFjx3DhwgX88ssvRgtGROKdziqFtlYPDyclOng4Sh2HiEgSTS5ujh8/3uh2FxcXDB8+HNu3b0dwcLDRghGReDe6pCKC3BuduoGIqDVocnFz4MABU+YgIiPg5H1ERJyhmMhq6PQCki4XA+B4GyJq3YxW3Pz3v//Fm2++aaynIyKRkrPVKNPUwtnOBt18XaSOQ0QkGaMVN99++y02bNhgrKcjIpFuLLkQHtQGCjnH2xBR6yV6VfCbiYuLM9ZTEVEzcLwNEVEdjrkhsgKCIHCxTCKi60S33Hz//feNbpfJZFCpVOjYsSMvCSdqYQlphSis0MLORo5eAa5SxyEikpTo4mbcuHGQyWQQBKHe9hvbZDIZBg8ejB07dqBNmzZGC0pEjcsqrsTML+vmoXqgtx/sbBQSJyIikpbobqm9e/ciIiICe/fuRWlpKUpLS7F3715ERkbihx9+wC+//ILCwkLMnTvXFHmJ6C8qNLV4buNRFFZo0d3XBW+N6yF1JCIiyYluuZk9ezY+/fRTDBw40LAtKioKKpUK06ZNw9mzZ7Fs2TJMmTLFqEGJqD69XsDLW0/gfE4ZPJzs8NmkfnBQGu0aASIiiyW65SY1NRUuLg3n0HBxcUFaWhoAoFOnTigoKLjzdER0Ux/sTcGec7lQ2sjx6cRw+LnZSx2JiMgsiC5uwsPDMW/ePOTn5xu25efnY/78+YiIiAAAXLx4EYGBgcZLSUT17Dh+FSsPpAIA3n24F/q24/g2IqIbRLdhr127FmPHjkVAQIChgMnMzESHDh2wc+dOAEB5eTlee+014yYlIgDA8YxizP/2FABg+rAQPBQWIHEiIiLzIhP+ftlTE+j1euzZswcXLlwAAHTp0gXDhw+HXG7+0+ao1Wq4urqitLS00e41InN2raQKY1f+ivwyDaK7eeHTp/tBztmIiagVEPP93azixpKxuCFLVamtxT9WJ+DsNTW6+jhj2/SBcLLjAGIiah3EfH836zdjXFwc4uLikJeXB71eX2/funXrmvOURHQLer2Aud+cxNlrarg7KrFmYj8WNkRENyH6t+Mbb7yBN998E/369YOvry9kMjaJE5naR3EXset0DmwVMnzydDgC3R2kjkREZLZEFzerV6/Ghg0b8PTTT5siDxH9zQ+nruGjuIsAgLfH9eLCmEREtyF6BLBWq603gR8Rmc6prBLM+fokAOC5wcF4NIJTLBAR3Y7o4ua5557Dl19+aYosRPQXuepqTP38KDS1egzr4omFo7tJHYmIyCKI7paqrq7Gp59+in379qF3796wtbWtt3/p0qVGC0fUWlXX6DDt86PIVWvQ0csJHz8eBgUv+SYiahLRxc2pU6cQGhoKADhz5ky9fRxcTHTnBEHAvG2ncDKrFG4Otlg7qR9cVLa3P5GIiAA0o7g5cOCAKXIQ0XUrD1zC/05eg41chlVPhqN9W0epIxERWRTzn1KYqBXZczYH/7enbubvN8f2xICQthInIiKyPE1quRk/fjw2bNgAFxcXjB8//pbHbt++3SjBiFqjd3efBwBMGtAeT0S2kzgNEZFlalJx4+rqahhP4+rqatJARK3VpbxypOZXwFYhw5yRXaSOQ0RksZpU3Kxfv77R+0RkPHvO5QAABoR4cAAxEdEdMNqYm1OnTkGpVBrr6YhanT1ncwEAI3t4S5yEiMiyGa24EQQBtbW1xno6olYlV12NE5klAIDh3VjcEBHdCaNeLcV5boiaZ8+5ulabsHZu8HJRSZyGiMiy8VJwIjOw52zdeJuRPXwkTkJEZPmaPImfWq2+5f6ysrI7DkPUGpVW1SAhtRAAMKI7u6SIiO5Uk4sbNze3W3Y7CYLAbimiZohPyUOtXkAnLyd08HSSOg4RkcVrcnHDZReITOPn611SI3iVFBGRUTS5uBk6dKgpcxC1StU1OsSn5AMARnTneBsiImPggGIiCf2WWoBKrQ4+Lir0DuDs30RExsDihkhCP5+puwR8RA9vjlkjIjISsyhuVq5ciaCgIKhUKkRGRiIxMfGmx27YsAEymazeTaXivCBkeXR6AfuSb8xKzC4pIiJjkby42bp1K2JiYrB48WIcO3YMffr0wciRI5GXl3fTc1xcXJCdnW24XblypQUTExlH0pViFFZo4aKyQf9gd6njEBFZDcmLm6VLl2Lq1KmYPHkyunfvjtWrV8PBwQHr1q276TkymQw+Pj6Gm7c3rzIhy3Nj4r6obt6wVUj+vyIRkdUw6m/UKVOmYNOmTU0+XqvVIikpCdHR0X8GkssRHR2NhISEm55XXl6O9u3bIzAwEGPHjsXZs2dveqxGo4Fara53I5KaIAiGJRe4UCYRkXEZtbhJS0vD66+/jtDQ0CYdX1BQAJ1O16DlxdvbGzk5OY2e06VLF6xbtw47d+7E5s2bodfrMXDgQGRlZTV6fGxsLFxdXQ23wMBAUT8TkSmczylDRlEl7GzkuLuzp9RxiIisSpPnuWmK+Ph4AMC5c+eM+bT1DBgwAAMGDDA8HjhwILp164ZPPvkEb731VoPjFy5ciJiYGMNjtVrNAockt+dsXavNkE6ecFAa9X9DIqJWzyS/Vbt3796k4zw8PKBQKJCbm1tve25uLnx8mnb1iK2tLcLCwnDp0qVG99vZ2cHOzq5Jz0XUUjgrMRGR6Yjultq4cSN+/PFHw+P58+fDzc0NAwcOFH3VklKpRHh4OOLi4gzb9Ho94uLi6rXO3IpOp8Pp06fh6+sr6rWJpJJZVIlz2WrIZUB0NxY3RETGJrq4WbJkCezt7QEACQkJWLlyJd577z14eHjg5ZdfFh0gJiYGa9aswcaNG5GcnIzp06ejoqICkydPBgBMnDgRCxcuNBz/5ptvYs+ePUhLS8OxY8fw1FNP4cqVK3juuedEvzaRFG4MJI4Icoe7o1LiNERE1kd0t1RmZiY6duwIANixYwcefvhhTJs2DYMGDcKwYcNEB5gwYQLy8/OxaNEi5OTkIDQ0FLt37zYMMs7IyIBc/mcNVlxcjKlTpyInJwdt2rRBeHg4fvvttyZ3hRFJbY+hS4oT9xERmYJMEARBzAleXl74+eefERYWhrCwMMTExODpp59Gamoq+vTpg/LyclNlNQq1Wg1XV1eUlpbCxcVF6jjUyhRVaNHvP3uhF4BD8+9BoLuD1JGIiCyCmO9v0S03w4cPx3PPPYewsDBcuHABo0ePBgCcPXsWQUFBzQpM1FrsS86FXgC6+7qwsCEiMhHRY25WrlyJAQMGID8/H99++y3atm0LAEhKSsLjjz9u9IBE1uTGJeBcS4qIyHREd0tZOnZLkVQqtbUIe3MvNLV6/DR7CLr58vNHRNRUYr6/Rbfc7N69G4cPHzY8XrlyJUJDQ/HEE0+guLhYfFqiVuKXC/nQ1OoR6G6Prj7OUschIrJaooubefPmGdZnOn36NObMmYPRo0cjPT293kzARFSfoUuquw9kMpnEaYiIrJfoAcXp6emGy66//fZbPPDAA1iyZAmOHTtmGFxMRPXV6PTYl1xX3PAScCIi0xLdcqNUKlFZWQkA2LdvH0aMGAEAcHd354rbRDeRmF4EdXUt2joqEd6+jdRxiIismuiWm8GDByMmJgaDBg1CYmIitm7dCgC4cOECAgICjB6QyBrcWEsqups3FHJ2SRERmZLolpsVK1bAxsYG27Ztw6pVq+Dv7w8A+OmnnzBq1CijBySydIIgGMbbcKFMIiLTE91y065dO/zwww8Ntn/44YdGCURkbU5llSJHXQ0HpQKDOnpIHYeIyOqJbrkBgNTUVLz22mt4/PHHkZeXB6Cu5ebs2bNGDUdkDfacq+uSGtbFEypbhcRpiIisn+ji5uDBg+jVqxeOHDmC7du3G9aSOnnyJBYvXmz0gESWjrMSExG1LNHFzYIFC/Cf//wHe/fuhVKpNGy/99578fvvvxs1HJGlS8svx8W8ctjIZRjWxUvqOERErYLo4ub06dN46KGHGmz38vJCQUGBUUIRWYs95+pabQaEtIWrva3EaYiIWgfRxY2bmxuys7MbbD9+/LjhyikiqnPjEnBO3EdE1HJEFzePPfYYXnnlFeTk5EAmk0Gv1+PXX3/F3LlzMXHiRFNkJLJIeepqHM8oAQAM78ZLwImIWoro4mbJkiXo2rUrAgMDUV5eju7du+Puu+/GwIED8dprr5kiI5FF2nt9uYXQQDf4uKokTkNE1HqInudGqVRizZo1eP3113HmzBmUl5cjLCwMnTp1MkU+Iov1MyfuIyKShOji5oZ27dqhXbt2xsxCZDXU1TVISK0bYD+iO8fbEBG1JNHFjU6nw4YNGxAXF4e8vDzo9fp6+/fv32+0cESW6sD5PNToBIR4OqKjl5PUcYiIWhXRxc3s2bOxYcMG3H///ejZsydkMi4CSPR3Ny4B51VSREQtT3Rxs2XLFnz99dcYPXq0KfIQmQVBEPBR3EXsOH4VShs57G0VUNkqYK9UwN627qZSKuBwfZvq+ra6+3LEn69bloSzEhMRtbxmDSju2LGjKbIQmY21h9OxbN/FO3oObxc79PZ3NVIiIiJqKtHFzZw5c/DRRx9hxYoV7JIiq3QgJQ9LdiUDAF6O7oyIoDaoqtHV3bQ6VBvu61FVc/2xtm5b5fX9Wp0eT9/VHnI5/x8hImppooubw4cP48CBA/jpp5/Qo0cP2NrWn1J++/btRgtH1NIu5ZVj1pfHoReACf0CMSuqI4t4IiILI7q4cXNza3RtKSJLV1pZg6mfH0WZphYRQW3w1jgOmCciskSii5v169ebIgeRpGp1erz05TGkF1TA380eq54Kh9JG9ATeRERkBpr127u2thb79u3DJ598grKyMgDAtWvXUF5ebtRwRC3lPz8m4/ClAjgoFVgzsR88nOykjkRERM0kuuXmypUrGDVqFDIyMqDRaDB8+HA4Ozvj3XffhUajwerVq02Rk8hkvkrMwIbfLgMAlj4aiu5+LtIGIiKiOyK65Wb27Nno168fiouLYW9vb9j+0EMPIS4uzqjhiEztSFohXt9xBgAwZ3hnjOrJeWmIiCyd6JabQ4cO4bfffoNSqay3PSgoCFevXjVaMCJTyyyqxPQvjqFWL+CB3r6YcS/nbyIisgaiW270ej10Ol2D7VlZWXB2djZKKCJTK9fUYurnR1FUoUUvf1e8/0gfXhlFRGQlRBc3I0aMwLJlywyPZTIZysvLsXjxYi7JQBZBrxfw8tYTOJ9TBk9nO3w6MRz2SoXUsYiIyEhEd0t98MEHGDlyJLp3747q6mo88cQTuHjxIjw8PPDVV1+ZIiORUX2wNwV7z+VCaSPHp0+Hw9fV/vYnERGRxRBd3AQEBODkyZPYsmULTp06hfLycjz77LN48skn6w0wJjJHO09cxcoDqQCAdx/uhbB2bSRORERExia6uAEAGxsbPPXUU8bOQmRSJzNLMH/bKQDA80M74KGwAIkTERGRKYgubr7//vtGt8tkMqhUKnTs2BHBwcF3HIzImHLV1Zj6+VFoavW4t6sX5o/sKnUkIiIyEdHFzbhx4yCTySAIQr3tN7bJZDIMHjwYO3bsQJs2bPIn6VXX6DDt86PIK9Ogk5cTPnosFAqu1k1EZLVEXy21d+9eREREYO/evSgtLUVpaSn27t2LyMhI/PDDD/jll19QWFiIuXPnmiIvkSiCIOCVb0/hZFYp3BxssXZSBJxVtrc/kYiILJbolpvZs2fj008/xcCBAw3boqKioFKpMG3aNJw9exbLli3DlClTjBqUqDnW/XoZO09cg41chv8+2Rft2jpIHYmIiExMdMtNamoqXFwarr3j4uKCtLQ0AECnTp1QUFBw5+mI7sDprFK881MyAOC1+7thYIiHxImIiKgliC5uwsPDMW/ePOTn5xu25efnY/78+YiIiAAAXLx4EYGBgcZLSSRSWXUNZnx1DDU6ASN7eGPSwCCpIxERUQsR3S21du1ajB07FgEBAYYCJjMzEx06dMDOnTsBAOXl5XjttdeMm5SoiQRBwGs7zuBKYSX83ezx3sNcWoGIqDURXdx06dIF586dw549e3DhwgXDtuHDh0Mur2sIGjdunFFDEonxTVIWdp64BoVcho8fD4WrAwcQExG1Js2axE8ul2PUqFEYNWqUsfMQ3ZFLeWVYvPMsACBmeGeEt3eXOBEREbW0JhU3H3/8cZOfcNasWc0OQ3Qnqmt0mPHlcVTV6DC4owemDw2ROhIREUmgScXNhx9+WO9xfn4+Kisr4ebmBgAoKSmBg4MDvLy8WNyQZN7+MRnnc8rg4aTE0gl9IOdEfURErVKTrpZKT0833N5++22EhoYiOTkZRUVFKCoqQnJyMvr27Yu33nrL1HmJGrX7TDY2/X4FAPDBo6HwclZJnIiIiKQiE/6+jsJthISEYNu2bQgLC6u3PSkpCY888gjS09ONGtDY1Go1XF1dUVpa2uh8PWR5Mosqcf/Hh6CursXzQztg4X3dpI5ERERGJub7W/Q8N9nZ2aitrW2wXafTITc3V+zTEd2RGp0es7cch7q6FqGBbpg7oovUkYiISGKii5uoqCg8//zzOHbsmGFbUlISpk+fjujoaKOGI7qdD/dewLGMEjirbLD88TDYKkR/pImIyMqI/iZYt24dfHx80K9fP9jZ2cHOzg79+/eHt7c3Pvvss2aFWLlyJYKCgqBSqRAZGYnExMQmnbdlyxbIZDLOq9NKHbqYj1UHUwEA74zvjUB3rhtFRETNmOfG09MTu3btwoULF3D+/HkAQNeuXdG5c+dmBdi6dStiYmKwevVqREZGYtmyZRg5ciRSUlLg5eV10/MuX76MuXPnYsiQIc16XbJs+WUavLz1JAQBeCKyHe7v7St1JCIiMhOiBxTfoNVqkZ6ejpCQENjYNGsuQABAZGQkIiIisGLFCgCAXq9HYGAgZs6ciQULFjR6jk6nw913340pU6bg0KFDKCkpwY4dOxo9VqPRQKPRGB6r1WoEBgZyQLEF0+sFTFqfiEMXC9DF2xk7ZwyCylYhdSwiIjIhkw4orqysxLPPPgsHBwf06NEDGRkZAICZM2finXfeEfVcWq0WSUlJ9cbqyOVyREdHIyEh4abnvfnmm/Dy8sKzzz5729eIjY2Fq6ur4cYFPS3fJ7+k4dDFAqhs5Vj+RBgLGyIiqkd0cbNw4UKcPHkS8fHxUKn+nEskOjoaW7duFfVcBQUF0Ol08Pb2rrfd29sbOTk5jZ5z+PBhrF27FmvWrGly3tLSUsMtMzNTVEYyL0lXivF/e1IAAP8e0wOdvZ0lTkREROZGdH/Sjh07sHXrVtx11131Vlru0aMHUlNTjRru78rKyvD0009jzZo18PDwaNI5NwY9k+UrrarBrK+OQ6cXMKaPHyZEsBWOiIgaEl3c5OfnNzrQt6Kiol6x0xQeHh5QKBQN5sfJzc2Fj49Pg+NTU1Nx+fJljBkzxrBNr9cDAGxsbJCSkoKQEK4nZI0EQcCCb0/hakkV2rk74O2Heor+vBERUesguluqX79++PHHHw2Pb3zBfPbZZxgwYICo51IqlQgPD0dcXJxhm16vR1xcXKPP1bVrV5w+fRonTpww3B588EHcc889OHHiBMfTWClBELD+18v46UwObOQyLH88DC4qW6ljERGRmRLdcrNkyRLcd999OHfuHGpra/HRRx/h3Llz+O2333Dw4EHRAWJiYjBp0iT069cP/fv3x7Jly1BRUYHJkycDACZOnAh/f3/ExsZCpVKhZ8+e9c6/sXjn37eTdTiRWYJ3fkrG72lFAIBXRnVFn0A3aUMREZFZE13cDB48GCdOnMA777yDXr16Yc+ePejbty8SEhLQq1cv0QEmTJiA/Px8LFq0CDk5OQgNDcXu3bsNg4wzMjIgl3PW2dYmLb8c/7cnBbtO1w0sVyrkmHp3MJ4dHCxxMiIiMnfNnufGUnHhTPOWp67GsriL2PpHJnR6ATIZ8HDfALw8vDP83eyljkdERBIR8/3d5JYbtVrdpONYMFBzqKtr8OnBNKw9nI6qGh0AIKqrF+aN6oKuPvxMERFR0zW5uHFzc7vl1SmCIEAmk0Gn0xklGLUOmlodNiVcwcoDl1BcWQMA6NvODQvu64b+we4SpyMiIkvU5OLmwIEDhvuCIGD06NH47LPP4O/vb5JgZN10egE7T1zFB3su4GpJFQAgxNMR80d1xYju3rzMm4iImq3Jxc3QoUPrPVYoFLjrrrvQoUMHo4ci6yUIAuIv5OPdn87jfE4ZAMDHRYWXh3fCw30DYKPg4HEiIrozzV/xkkikzKJKzNt20nBZt4vKBtOHdcQzA4Ngr+T6UEREZBwsbqhFFJRr8PTaI7hcWAmljRyTBwZh+rAQuDkopY5GRERW5o6KG46LoKYo19Ri8vo/cLmwEgFt7PHV1LsQ6O4gdSwiIrJSTS5uxo8fX+9xdXU1XnjhBTg6Otbbvn37duMkI6ugrdVj+uYknL5aCndHJT6f0p+FDRERmVSTixtXV9d6j5966imjhyHrotcLmLftJA5dLICDUoH1z0Sgg6eT1LGIiMjKNbm4Wb9+vSlzkJURBAFv70rGzhPXYCOXYdVT4VwTioiIWgSvuyWT+PSXutmGAeD9f/TG0M6eEiciIqLWoknFzQsvvICsrKwmPeHWrVvxxRdf3FEosmzbj2Uh9qfzAIBXR3fDQ2EBEiciIqLWpEndUp6enujRowcGDRqEMWPGoF+/fvDz84NKpUJxcTHOnTuHw4cPY8uWLfDz88Onn35q6txkpg6k5GH+tlMAgKlDgjH1bk7ySERELavJq4Ln5ubis88+w5YtW3Du3Ll6+5ydnREdHY3nnnsOo0aNMklQY+Gq4KZzPKMYT6w5gqoaHcaF+mHpo6GQyzldABER3Tkx399NLm7+qri4GBkZGaiqqoKHhwdCQkIsZs4bFjemkZpfjkdW/YbiyhoM6eSBtZMioLThkC4iIjIOMd/foibxq62txZIlSzBlyhT06dPnjkKS9chVV2Pi2kQUV9agT4ArVj8VzsKGiIgkI+obyMbGBu+99x5qa2tNlYcsTGlVDSatS8TVkioEezhi3TMRcLTjqh5ERCQd0X9eR0VF4eDBg6bIQhamukaHqZ8fxfmcMng62+HzKf3R1slO6lhERNTKif4T+7777sOCBQtw+vRphIeHN1h+4cEHHzRaODJfOr2Af245gcT0IjjZ2WDD5Aguq0BERGZB9IBiufzmjT0ymQw6ne6OQ5kSBxTfOUEQ8NqOM/jiSAaUCjk2TInAwBAPqWMREZEVM9mAYgDQ6/XNDkbWYfn+S/jiSAZkMuDDCaEsbIiIyKyIGnNTU1MDGxsbnDlzxlR5yMxdyivDh/suAADeeLAH7u/tK3EiIiKi+kQVN7a2tmjXrp3Zdz2R6fz3QCoEARje3RsTBwRJHYeIiKgB0VdLvfrqq/jXv/6FoqIiU+QhM3alsAI7T14DAMy8t6PEaYiIiBoneszNihUrcOnSJfj5+aF9+/YNrpY6duyY0cKReVl9MBU6vYChnT3RO8BN6jhERESNEl3cjBs3zgQxyNxdK6nCtqS6leHZakNEROZMdHGzePFiU+QgM/fpL2mo0Qm4q4M7+gW5Sx2HiIjoppo9T35SUhKSk5MBAD169EBYWJjRQpF5ySurxleJGQCAmfd2kjgNERHRrYkubvLy8vDYY48hPj4ebm5uAICSkhLcc8892LJlCzw9PY2dkSS29lA6NLV6hLVzw8CQtlLHISIiuiXRV0vNnDkTZWVlOHv2LIqKilBUVIQzZ85ArVZj1qxZpshIEiqu0GLT71cA1I21kclkEiciIiK6NdEtN7t378a+ffvQrVs3w7bu3btj5cqVGDFihFHDkfTW/5qOSq0O3X1dcE8XL6njEBER3Zbolhu9Xg9bW9sG221tbbk0g5VRV9dg/W+XAbDVhoiILIfo4ubee+/F7Nmzce3aNcO2q1ev4uWXX0ZUVJRRw5G0NiVcQVl1LTp6OWFkDx+p4xARETWJ6OJmxYoVUKvVCAoKQkhICEJCQhAcHAy1Wo3ly5ebIiNJoFJbi88OpQEAZtzTEXI5W22IiMgyiB5zExgYiGPHjmHfvn04f/48AKBbt26Ijo42ejiSzpdHMlBcWYP2bR3wABfHJCIiC9KseW5kMhmGDx+O4cOHGzsPmYHqGh0++aWu1ebFYSGwUYhu4CMiIpJMk7+19u/fj+7du0OtVjfYV1paih49euDQoUNGDUfS+OZoJvLLNPBzVeGhsACp4xAREYnS5OJm2bJlmDp1KlxcXBrsc3V1xfPPP4+lS5caNRy1PG2tHqsP1rXavDAsBEobttoQEZFlafI318mTJzFq1Kib7h8xYgSSkpKMEoqks+P4VVwtqYKnsx0e7RcodRwiIiLRmlzc5ObmNjq/zQ02NjbIz883SiiSRq1Oj//GXwIATBvSASpbhcSJiIiIxGtycePv748zZ87cdP+pU6fg68uraizZj6ezcbmwEm0cbPFEZDup4xARETVLk4ub0aNH4/XXX0d1dXWDfVVVVVi8eDEeeOABo4ajlqPXC1ixv67V5tnBwXC0a/aC8URERJKSCYIgNOXA3Nxc9O3bFwqFAjNmzECXLl0AAOfPn8fKlSuh0+lw7NgxeHt7mzTwnVKr1XB1dUVpaWmjg6Nbq91nsvHC5mNwVtng1wX3wkV18y5IIiKilibm+7vJf557e3vjt99+w/Tp07Fw4ULcqIlkMhlGjhyJlStXmn1hQ40TBAHLr7faPDMwiIUNERFZNFF9D+3bt8euXbtQXFyMS5cuQRAEdOrUCW3atDFVPmoB8Sn5OHtNDQelApMHBUsdh4iI6I40a2BFmzZtEBERYewsJAFBEPDx/osAgKfuag93R6XEiYiIiO4MZ2hr5RJSC3E8owRKGzmeG8JWGyIisnwsblq5G2NtHo8IhJezSuI0REREd47FTSt29HIREtIKYauQYdrQEKnjEBERGQWLm1ZsxYG6VpuH+wbA381e4jRERETGYRbFzcqVKxEUFASVSoXIyEgkJibe9Njt27ejX79+cHNzg6OjI0JDQ7Fp06YWTGsdTmeVIj4lH3IZMH0YW22IiMh6SF7cbN26FTExMVi8eDGOHTuGPn36YOTIkcjLy2v0eHd3d7z66qtISEjAqVOnMHnyZEyePBk///xzCye3XFVaHV759hQA4ME+fmjf1lHiRERERMbT5BmKTSUyMhIRERFYsWIFAECv1yMwMBAzZ87EggULmvQcffv2xf3334+33nrrtse29hmKBUHAnK9PYvvxq3B3VOKHmYPhxy4pIiIyc2K+vyVtudFqtUhKSkJ0dLRhm1wuR3R0NBISEm57viAIiIuLQ0pKCu6+++5Gj9FoNFCr1fVurdnG3y5j+/GrUMhlWPFEGAsbIiKyOpIWNwUFBdDpdA2WbfD29kZOTs5NzystLYWTkxOUSiXuv/9+LF++HMOHD2/02NjYWLi6uhpugYGBRv0ZLEliehH+82MyAGDhfV0xMMRD4kRERETGJ/mYm+ZwdnbGiRMn8Mcff+Dtt99GTEwM4uPjGz124cKFKC0tNdwyMzNbNqyZyCmtxotfJKFWL2BMHz88O5gT9hERkXVq1vILxuLh4QGFQoHc3Nx623Nzc+Hj43PT8+RyOTp27AgACA0NRXJyMmJjYzFs2LAGx9rZ2cHOzs6ouS2NplaHFzYnoaBci64+znj34V6QyWRSxyIiIjIJSVtulEolwsPDERcXZ9im1+sRFxeHAQMGNPl59Ho9NBqNKSJahX9/fw4nMkvgorLBJ0+Hw0EpaU1LRERkUpJ/y8XExGDSpEno168f+vfvj2XLlqGiogKTJ08GAEycOBH+/v6IjY0FUDeGpl+/fggJCYFGo8GuXbuwadMmrFq1Ssofw2xtSczAV4kZkMmAjx4P42XfRERk9SQvbiZMmID8/HwsWrQIOTk5CA0Nxe7duw2DjDMyMiCX/9nAVFFRgRdffBFZWVmwt7dH165dsXnzZkyYMEGqH8FsHc8oxqKdZwEAMdGdcU8XL4kTERERmZ7k89y0tNYyz01+mQZjlh9Gjroaw7t745OnwiGXc5wNERFZJouZ54ZMo0anx0tfHkOOuhodPB2x9NE+LGyIiKjVYHFjhWJ3nUdiehEclQp8+nQ4nFW2UkciIiJqMSxurMzOE1ex7td0AMAHj4aio5ezxImIiIhaFosbK3L2WqlhQcyX7gnBqJ43nyuIiIjIWrG4sRIllVq8sDkJ1TV63N3ZEzHDu0gdiYiISBIsbqyATi9g5lfHkVlUhXbuDvj4sVAoOICYiIhaKRY3VuCDPSk4dLEAKls5Vj8VDjcHpdSRiIiIJMPixsLtPpON/8anAgDefbg3uvtZ79w9RERETSH5DMUkjiAISMktQ1xyHuKSc3E8swQA8OzgYIwN9Zc2HBERkRlgcWMBNLU6HEkrQlxyLuLO5yGruKre/tG9fLDwvq4SpSMiIjIvLG7MVGG5BvvP5yEuOQ+HLuajQqsz7LOzkWNQRw9EdfPCvV294OtqL2FSIiIi88LixkwIgoALueXYl5xr6G7666pfns52iOrqhahu3hjUsS0clPxPR0RE1Bh+Q0ooT12NhLRC/J5WiEMXCxp0N/Xwc0FUN29Ed/NCTz9Xrg9FRETUBCxuWlBeWTWOpBUZCpq0/Ip6+9ndREREdOdY3JhQQbnmejFTgN/TinApr7zefpmsrnXmruC2GBBSd2N3ExER0Z3hN6kRFVVocSSt0NAycyG3YTHTzccFd3WoK2T6B7nD1YErdhMRERkTixsj2XM2B9M2JTXY3tXH2VDMRAa7c/ZgIiIiE2NxYyQ9/V0BAF28nXFXB/e6lpngtnB3ZDFDRETUkljcGImfmz2OvT6cxQwREZHEuLaUEbGwISIikh6LGyIiIrIqLG6IiIjIqrC4ISIiIqvC4oaIiIisCosbIiIisiosboiIiMiqsLghIiIiq8LihoiIiKwKixsiIiKyKixuiIiIyKqwuCEiIiKrwuKGiIiIrAqLGyIiIrIqNlIHaGmCIAAA1Gq1xEmIiIioqW58b9/4Hr+VVlfclJWVAQACAwMlTkJERERilZWVwdXV9ZbHyISmlEBWRK/X49q1a3B2doZMJjPqc6vVagQGBiIzMxMuLi5GfW5rwffo1vj+3B7fo9vje3RrfH9uzxzfI0EQUFZWBj8/P8jltx5V0+pabuRyOQICAkz6Gi4uLmbzYTBXfI9uje/P7fE9uj2+R7fG9+f2zO09ul2LzQ0cUExERERWhcUNERERWRUWN0ZkZ2eHxYsXw87OTuooZovv0a3x/bk9vke3x/fo1vj+3J6lv0etbkAxERERWTe23BAREZFVYXFDREREVoXFDREREVkVFjdERERkVVjcGMnKlSsRFBQElUqFyMhIJCYmSh3JbPz73/+GTCard+vatavUsST1yy+/YMyYMfDz84NMJsOOHTvq7RcEAYsWLYKvry/s7e0RHR2NixcvShNWIrd7j5555pkGn6tRo0ZJE1YCsbGxiIiIgLOzM7y8vDBu3DikpKTUO6a6uhovvfQS2rZtCycnJzz88MPIzc2VKHHLa8p7NGzYsAafoxdeeEGixC1r1apV6N27t2GivgEDBuCnn34y7Lfkzw+LGyPYunUrYmJisHjxYhw7dgx9+vTByJEjkZeXJ3U0s9GjRw9kZ2cbbocPH5Y6kqQqKirQp08frFy5stH97733Hj7++GOsXr0aR44cgaOjI0aOHInq6uoWTiqd271HADBq1Kh6n6uvvvqqBRNK6+DBg3jppZfw+++/Y+/evaipqcGIESNQUVFhOObll1/G//73P3zzzTc4ePAgrl27hvHjx0uYumU15T0CgKlTp9b7HL333nsSJW5ZAQEBeOedd5CUlISjR4/i3nvvxdixY3H27FkAFv75EeiO9e/fX3jppZcMj3U6neDn5yfExsZKmMp8LF68WOjTp4/UMcwWAOG7774zPNbr9YKPj4/w/vvvG7aVlJQIdnZ2wldffSVBQun9/T0SBEGYNGmSMHbsWEnymKO8vDwBgHDw4EFBEOo+M7a2tsI333xjOCY5OVkAICQkJEgVU1J/f48EQRCGDh0qzJ49W7pQZqZNmzbCZ599ZvGfH7bc3CGtVoukpCRER0cbtsnlckRHRyMhIUHCZObl4sWL8PPzQ4cOHfDkk08iIyND6khmKz09HTk5OfU+U66uroiMjORn6m/i4+Ph5eWFLl26YPr06SgsLJQ6kmRKS0sBAO7u7gCApKQk1NTU1Pscde3aFe3atWu1n6O/v0c3fPHFF/Dw8EDPnj2xcOFCVFZWShFPUjqdDlu2bEFFRQUGDBhg8Z+fVrdwprEVFBRAp9PB29u73nZvb2+cP39eolTmJTIyEhs2bECXLl2QnZ2NN954A0OGDMGZM2fg7OwsdTyzk5OTAwCNfqZu7KO6Lqnx48cjODgYqamp+Ne//oX77rsPCQkJUCgUUsdrUXq9Hv/85z8xaNAg9OzZE0Dd50ipVMLNza3esa31c9TYewQATzzxBNq3bw8/Pz+cOnUKr7zyClJSUrB9+3YJ07ac06dPY8CAAaiuroaTkxO+++47dO/eHSdOnLDozw+LGzK5++67z3C/d+/eiIyMRPv27fH111/j2WeflTAZWbLHHnvMcL9Xr17o3bs3QkJCEB8fj6ioKAmTtbyXXnoJZ86cafVj2W7lZu/RtGnTDPd79eoFX19fREVFITU1FSEhIS0ds8V16dIFJ06cQGlpKbZt24ZJkybh4MGDUse6Y+yWukMeHh5QKBQNRpDn5ubCx8dHolTmzc3NDZ07d8alS5ekjmKWbnxu+JkSp0OHDvDw8Gh1n6sZM2bghx9+wIEDBxAQEGDY7uPjA61Wi5KSknrHt8bP0c3eo8ZERkYCQKv5HCmVSnTs2BHh4eGIjY1Fnz598NFHH1n854fFzR1SKpUIDw9HXFycYZter0dcXBwGDBggYTLzVV5ejtTUVPj6+kodxSwFBwfDx8en3mdKrVbjyJEj/EzdQlZWFgoLC1vN50oQBMyYMQPfffcd9u/fj+Dg4Hr7w8PDYWtrW+9zlJKSgoyMjFbzObrde9SYEydOAECr+Rz9nV6vh0ajsfzPj9Qjmq3Bli1bBDs7O2HDhg3CuXPnhGnTpglubm5CTk6O1NHMwpw5c4T4+HghPT1d+PXXX4Xo6GjBw8NDyMvLkzqaZMrKyoTjx48Lx48fFwAIS5cuFY4fPy5cuXJFEARBeOeddwQ3Nzdh586dwqlTp4SxY8cKwcHBQlVVlcTJW86t3qOysjJh7ty5QkJCgpCeni7s27dP6Nu3r9CpUyehurpa6ugtYvr06YKrq6sQHx8vZGdnG26VlZWGY1544QWhXbt2wv79+4WjR48KAwYMEAYMGCBh6pZ1u/fo0qVLwptvvikcPXpUSE9PF3bu3Cl06NBBuPvuuyVO3jIWLFggHDx4UEhPTxdOnTolLFiwQJDJZMKePXsEQbDszw+LGyNZvny50K5dO0GpVAr9+/cXfv/9d6kjmY0JEyYIvr6+glKpFPz9/YUJEyYIly5dkjqWpA4cOCAAaHCbNGmSIAh1l4O//vrrgre3t2BnZydERUUJKSkp0oZuYbd6jyorK4URI0YInp6egq2trdC+fXth6tSpreoPisbeGwDC+vXrDcdUVVUJL774otCmTRvBwcFBeOihh4Ts7GzpQrew271HGRkZwt133y24u7sLdnZ2QseOHYV58+YJpaWl0gZvIVOmTBHat28vKJVKwdPTU4iKijIUNoJg2Z8fmSAIQsu1ExERERGZFsfcEBERkVVhcUNERERWhcUNERERWRUWN0RERGRVWNwQERGRVWFxQ0RERFaFxQ0RERFZFRY3REREZFVY3BAREZFVYXFDRGbhmWeewbhx46SOQURWgMUNEVEjtFqt1BGIqJlY3BCR2Vu6dCl69eoFR0dHBAYG4sUXX0R5eTkAoKKiAi4uLti2bVu9c3bs2AFHR0eUlZUBADIzM/Hoo4/Czc0N7u7uGDt2LC5fvmw4/kbL0dtvvw0/Pz906dKlxX4+IjIuFjdEZPbkcjk+/vhjnD17Fhs3bsT+/fsxf/58AICjoyMee+wxrF+/vt4569evxyOPPAJnZ2fU1NRg5MiRcHZ2xqFDh/Drr7/CyckJo0aNqtdCExcXh5SUFOzduxc//PBDi/6MRGQ8XBWciMzCM888g5KSEuzYseO2x27btg0vvPACCgoKAACJiYkYOHAgMjMz4evri7y8PPj7+2Pfvn0YOnQoNm/ejP/85z9ITk6GTCYDUNft5Obmhh07dmDEiBF45plnsHv3bmRkZECpVJryRyUiE2PLDRGZvX379iEqKgr+/v5wdnbG008/jcLCQlRWVgIA+vfvjx49emDjxo0AgM2bN6N9+/a4++67AQAnT57EpUuX4OzsDCcnJzg5OcHd3R3V1dVITU01vE6vXr1Y2BBZARY3RGTWLl++jAceeAC9e/fGt99+i6SkJKxcuRJA/UG/zz33HDZs2ACgrktq8uTJhlaa8vJyhIeH48SJE/VuFy5cwBNPPGF4DkdHx5b7wYjIZGykDkBEdCtJSUnQ6/X44IMPIJfX/T329ddfNzjuqaeewvz58/Hxxx/j3LlzmDRpkmFf3759sXXrVnh5ecHFxaXFshORNNhyQ0Rmo7S0tEHrioeHB2pqarB8+XKkpaVh06ZNWL16dYNz27Rpg/Hjx2PevHkYMWIEAgICDPuefPJJeHh4YOzYsTh06BDS09MRHx+PWbNmISsrqyV/RCJqASxuiMhsxMfHIywsrN5t06ZNWLp0Kd5991307NkTX3zxBWJjYxs9/9lnn4VWq8WUKVPqbXdwcMAvv/yCdu3aYfz48ejWrRueffZZVFdXsyWHyArxaikishqbNm3Cyy+/jGvXrnFgMFErxjE3RGTxKisrkZ2djXfeeQfPP/88CxuiVo7dUkRk8d577z107doVPj4+WLhwodRxiEhi7JYiIiIiq8KWGyIiIrIqLG6IiIjIqrC4ISIiIqvC4oaIiIisCosbIiIisiosboiIiMiqsLghIiIiq8LihoiIiKzK/wNvLWENFAJfZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lu_corrs)\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Corr(Hedgeness, Ling.Uncertain.Feat.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7985b45-bec3-4dec-9a1c-6477251efdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Corr(Hedgeness, Sem.Uncertain.Feat.)')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sem_uncertainty_scores = np.array([\n",
    "    results_merged[i]['semantic entropy'] for i in ds_idx\n",
    "])\n",
    "\n",
    "lu_corrs = []\n",
    "for l in range(32):\n",
    "    corr_l = spearmanr(luf_cache_all[l].numpy(), sem_uncertainty_scores)\n",
    "    lu_corrs.append(corr_l[0])\n",
    "\n",
    "plt.plot(lu_corrs)\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Corr(Hedgeness, Sem.Uncertain.Feat.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bfd7c3e-4dc6-4f15-9d59-6436be4c5e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'when was the last time anyone was on the moon',\n",
       " 'model answers': ['The last time humans visited the moon was during the Apollo 17 mission in December 1972, specifically on December 19-20, 1972, when astronauts Eugene Cernan and Harrison Schmitt spent about 75 hours on the lunar',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when Eugene Cernan and Harrison Schmitt spent three days on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission, which took place in December 1972, with astronauts Eugene Cernan and Harrison Schmitt spending approximately three days on the lunar surface.',\n",
       "  'The last time humans were on the moon was during the Apollo 17 mission, which took place from December 7 to 19, 1972.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission, which landed on December 11, 1972, with astronauts Eugene Cernan and Harrison Schmitt spending approximately three days on the lunar surface.',\n",
       "  'The last time humans were on the moon was during the Apollo 17 mission, which landed on December 11, 1972, with astronauts Eugene Cernan and Harrison Schmitt spending about 75 hours on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when astronauts Eugene Cernan, Ronald Evans, and Harrison Schmitt spent three days on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when Eugene Cernan and Harrison Schmitt spent three days on the lunar surface.',\n",
       "  'The last time humans were on the moon was during the Apollo 17 mission in December 1972, with astronauts Eugene Cernan and Harrison Schmitt spending a total of 75 hours and 48 minutes on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when astronauts Eugene Cernan and Harrison Schmitt spent approximately three days on the lunar surface.',\n",
       "  'The last time humans were on the moon was during the Apollo 17 mission in December 1972, when Eugene Cernan and Harrison Schmitt spent three days on the lunar surface, and the United States has not had a manned mission to the',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission, which landed on December 11, 1972, and the astronauts returned to Earth on December 19, 1972.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission, which took place in December 1972, specifically on December 11-19, 1972.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when astronauts Eugene Cernan and Harrison Schmitt spent three days on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when Eugene Cernan and Harrison Schmitt spent three days on the lunar surface.',\n",
       "  \"The last time humans visited the moon was during the Apollo 17 mission in December 1972, when astronauts Eugene Cernan and Harrison Schmitt spent three days on the lunar surface, although it's possible that uncrewed spacecraft may have visited\",\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when astronauts Eugene Cernan, Ronald Evans, and Harrison Schmitt spent three days on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when astronauts Eugene Cernan and Harrison Schmitt spent three days on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, when astronauts Eugene Cernan, Ronald Evans, and Harrison Schmitt spent approximately three days on the lunar surface.',\n",
       "  'The last time humans visited the moon was during the Apollo 17 mission in December 1972, with astronauts Eugene Cernan, Ronald Evans, and Harrison Schmitt spending three days on the lunar surface.'],\n",
       " 'decisiveness score': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'nli labels': [[2, 2, 2, 0, 0, 0, 1, 2, 1, 2, 1, 1, 0, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [2, 2, 2, 0, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [0, 2, 2, 0, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2],\n",
       "  [1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1],\n",
       "  [1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2],\n",
       "  [1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2]],\n",
       " 'semantic entropy': -1.4100494384765625,\n",
       " 'answer log likelihoods': [-0.12751349806785583,\n",
       "  -0.12024432420730591,\n",
       "  -0.2567942142486572,\n",
       "  -0.2726327180862427,\n",
       "  -0.1796317845582962,\n",
       "  -0.17035174369812012,\n",
       "  -0.14321303367614746,\n",
       "  -0.12024432420730591,\n",
       "  -0.14338059723377228,\n",
       "  -0.16167688369750977,\n",
       "  -0.3856346905231476,\n",
       "  -0.152629092335701,\n",
       "  -0.30163994431495667,\n",
       "  -0.10558183491230011,\n",
       "  -0.12024432420730591,\n",
       "  -0.26471084356307983,\n",
       "  -0.14321303367614746,\n",
       "  -0.10558183491230011,\n",
       "  -0.19701296091079712,\n",
       "  -0.18738366663455963],\n",
       " 'linguistic uncertainty': 0.004999999999999999,\n",
       " 'dataset name': 'nq_open',\n",
       " 'true answers': ['14 December 1972 UTC', 'December 1972']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_merged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c07a93-41b2-4e63-b489-0ee5c3396ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46542819-7949-4066-8954-679f12834d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0facec8a-8c6c-4317-8d90-b5b767a6f58f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                                            | 13/1431 [00:14<25:37,  1.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     26\u001b[0m     messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     27\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m answer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs[:, inputs\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m results_with_lufi\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     37\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: question, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel answer with lufi\u001b[39m\u001b[38;5;124m'\u001b[39m: answer}\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/generation/utils.py:3038\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3031\u001b[0m     streamer\u001b[38;5;241m.\u001b[39mput(next_tokens\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m   3032\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3033\u001b[0m     outputs,\n\u001b[1;32m   3034\u001b[0m     model_kwargs,\n\u001b[1;32m   3035\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3036\u001b[0m )\n\u001b[0;32m-> 3038\u001b[0m unfinished_sequences \u001b[38;5;241m=\u001b[39m unfinished_sequences \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m~\u001b[39m\u001b[43mstopping_criteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3039\u001b[0m this_peer_finished \u001b[38;5;241m=\u001b[39m unfinished_sequences\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3040\u001b[0m cur_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:511\u001b[0m, in \u001b[0;36mStoppingCriteriaList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m is_done \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), \u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m criteria \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 511\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m is_done \u001b[38;5;241m|\u001b[39m \u001b[43mcriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_done\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:502\u001b[0m, in \u001b[0;36mEosTokenCriteria.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    494\u001b[0m         input_ids[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token_id\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_done\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run luf ablation on **certain** examples with varying intervention strengths\n",
    "remove_all_hooks(model)\n",
    "torch.cuda.empty_cache()\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lufa_alphas = np.arange(-2., 2.1, 0.5)\n",
    "# lufa_alphas = [2.]\n",
    "layer_idx = list(range(32))\n",
    "for alpha in lufa_alphas:\n",
    "    \n",
    "    lu_def_cache = {}\n",
    "    for l in layer_idx:\n",
    "        mean_luf_l, std_luf_l = luf_cache_uncertain[l]\n",
    "        def_luf_l = mean_luf_l + alpha * std_luf_l\n",
    "        lu_def_cache[l] = def_luf_l\n",
    "\n",
    "    register_feature_ablation_hook(model, ling_uncertain_feats, lu_def_cache, layer_idx)\n",
    "    results_with_lufi = []\n",
    "    for question in tqdm(questions_certain):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\\nAnswer: \"},\n",
    "        ]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=True, add_generation_prompt=True, \n",
    "            return_tensors=\"pt\", return_dict=True\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=50,\n",
    "                do_sample=False\n",
    "            )\n",
    "        answer = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "        results_with_lufi.append(\n",
    "            {'question': question, 'model answer with lufi': answer}\n",
    "        )\n",
    "        # print(results_with_lufi[-1])\n",
    "        # print('\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "777d27d6-f84b-4648-a889-7d84d24ec6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2. , -1.5, -1. , -0.5,  0. ,  0.5,  1. ,  1.5,  2. ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(-2., 2.1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0990ee34-f2a0-43ff-87ed-c0cc69667977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                | 1/1431 [00:02<52:08,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '\"The song \"\"If I Ruled The World\"\" comes from which musical?\"', 'model answer with lufi': 'I\\'m not aware of any information about a song called \"If I Ruled The World\" from a specific musical, but there is a song with this title by the British hip-hop group LaFace Records, which was released in 1996 by'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                               | 2/1431 [00:04<51:04,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Riff, Bernado and Joyboy are all characters in which musical?', 'model answer with lufi': 'I\\'m not aware of any information about musical characters named Riff, Bernado, and Joyboy. However, I can tell you that Riff is a character from the musical \"West Side Story,\" Bernardo is also a character from \"West'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                               | 3/1431 [00:05<40:22,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which city was visited by Prince William in March 2011 after suffering two earthquakes in the preceeding six months?', 'model answer with lufi': \"I'm unable to verify which city was visited by Prince William in March 2011 after suffering two earthquakes in the preceding six months.\"}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                               | 4/1431 [00:06<35:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'The nickname for Dumfries became the name of which Scottish football club?', 'model answer with lufi': \"I'm sorry but I am unable to verify the name of the Scottish football club that was nicknamed after the town of Dumfries.\"}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                               | 4/1431 [00:07<45:49,  1.93s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     26\u001b[0m     messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     27\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m answer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs[:, inputs\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m results_with_lufi\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     37\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: question, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel answer with lufi\u001b[39m\u001b[38;5;124m'\u001b[39m: answer}\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:617\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    605\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    606\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    615\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 617\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    619\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run luf ablation on **uncertain** examples with varying intervention strengths\n",
    "remove_all_hooks(model)\n",
    "torch.cuda.empty_cache()\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# lufa_alphas = np.arange(-2., 2.1, 0.5)\n",
    "lufa_alphas = [5.]\n",
    "layer_idx = list(range(32))\n",
    "for alpha in lufa_alphas:\n",
    "    \n",
    "    lu_def_cache = {}\n",
    "    for l in layer_idx:\n",
    "        mean_luf_l, std_luf_l = luf_cache_certain[l]\n",
    "        def_luf_l = mean_luf_l + alpha * std_luf_l\n",
    "        lu_def_cache[l] = def_luf_l\n",
    "\n",
    "    register_feature_ablation_hook(model, ling_uncertain_feats, lu_def_cache, layer_idx)\n",
    "    results_with_lufi = []\n",
    "    for question in tqdm(questions_uncertain):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\\nAnswer: \"},\n",
    "        ]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=True, add_generation_prompt=True, \n",
    "            return_tensors=\"pt\", return_dict=True\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=50,\n",
    "                do_sample=False\n",
    "            )\n",
    "        answer = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "        results_with_lufi.append(\n",
    "            {'question': question, 'model answer with lufi': answer}\n",
    "        )\n",
    "        print(results_with_lufi[-1])\n",
    "        print('\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094aa9a-1c0a-4fff-b117-ebae0e369c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
